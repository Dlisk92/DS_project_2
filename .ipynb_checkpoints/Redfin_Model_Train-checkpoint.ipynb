{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from pyearth import Earth\n",
    "\n",
    "import gc; gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_Housing_Data_vDL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'price'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cols = ['sqft_living', 'lat', 'long', 'year']\n",
    "cat_cols = ['bedrooms', 'bathrooms', 'zipcode']\n",
    "used_cols =  real_cols + cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[used_cols], df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s(0) + s(1) + s(2) + s(3) + te(1, 2) + te(0, 1, 2) + te(4, 5) + te(1, 2, 6) + f(4) + f(5) + f(6)\n"
     ]
    }
   ],
   "source": [
    "from pygam.terms import s as spline\n",
    "from pygam.terms import f as factor\n",
    "from pygam.terms import te as tensor\n",
    "\n",
    "\n",
    "# DEFINE TERMS:\n",
    "#   * splines - for continuous\n",
    "#   * factors - for categorical/discrete \n",
    "#        (assumption: label encoded w/ 0 to level_size-1)\n",
    "#   * tensors - for any interactions\n",
    "\n",
    "# create the term list\n",
    "term_list = []\n",
    "for i, col in enumerate(used_cols):\n",
    "    if col in real_cols:\n",
    "        term_list.append(spline(i))\n",
    "\n",
    "# add the x1 and x2 interaction term\n",
    "term_list.append(tensor(1, 2))\n",
    "term_list.append(tensor(0, 1, 2))\n",
    "term_list.append(tensor(4, 5))\n",
    "term_list.append(tensor(1, 2, 6))\n",
    "\n",
    "\n",
    "\n",
    "# term_list.append(tensor(7, 8, 10))\n",
    "# term_list.append(tensor(0, 4))\n",
    "# term_list.append(tensor(0, 1, 2, 3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# factors\n",
    "for i, col in enumerate(used_cols):\n",
    "    if col in cat_cols:\n",
    "        term_list.append(factor(i))\n",
    "\n",
    "\n",
    "# create the terms and model\n",
    "terms = np.sum(term_list)\n",
    "print(terms)\n",
    "# gam = LinearGAM(terms=terms).gridsearch(X.values, y.values)\n",
    "# gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (11 of 11) |########################| Elapsed Time: 0:20:28 Time:  0:20:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAM                                                                                                       \n",
      "=============================================== ==========================================================\n",
      "Distribution:                         GammaDist Effective DoF:                                    416.2996\n",
      "Link Function:                          LogLink Log Likelihood:                               -272396.8467\n",
      "Number of Samples:                        21263 AIC:                                           545628.2925\n",
      "                                                AICc:                                          545645.0408\n",
      "                                                GCV:                                                0.0386\n",
      "                                                Scale:                                              0.0397\n",
      "                                                Pseudo R-Squared:                                   0.8773\n",
      "==========================================================================================================\n",
      "Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   \n",
      "================================= ==================== ============ ============ ============ ============\n",
      "s(0)                              [0.001]              20           19.8         2.43e-03     **          \n",
      "s(1)                              [0.001]              20           18.9         1.11e-16     ***         \n",
      "s(2)                              [0.001]              20           18.5         1.11e-16     ***         \n",
      "s(3)                              [0.001]              20           1.2          1.11e-16     ***         \n",
      "te(1, 2)                          [0.001 0.001]        100          53.7         1.11e-16     ***         \n",
      "te(0, 1, 2)                       [0.001 0.001 0.001]  1000         154.4        1.11e-16     ***         \n",
      "te(4, 5)                          [0.001 0.001]        100          29.8         1.11e-16     ***         \n",
      "te(1, 2, 6)                       [0.001 0.001 0.001]  1000         106.7        1.11e-16     ***         \n",
      "f(4)                              [0.001]              5            0.0          8.55e-01                 \n",
      "f(5)                              [0.001]              26           9.4          1.35e-06     ***         \n",
      "f(6)                              [0.001]              70           3.9          1.11e-16     ***         \n",
      "intercept                                              1            0.0          1.11e-16     ***         \n",
      "==========================================================================================================\n",
      "Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\n",
      "         which can cause p-values to appear significant when they are not.\n",
      "\n",
      "WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\n",
      "         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\n",
      "         are typically lower than they should be, meaning that the tests reject the null too readily.\n"
     ]
    }
   ],
   "source": [
    "# Playing with distribution assumptions and link functions\n",
    "from pygam import GAM\n",
    "\n",
    "\n",
    "gam = GAM(terms=terms, distribution='gamma', link='log')\n",
    "gam.gridsearch(X.values, y.values)\n",
    "gam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error train:  77393.24177901633\n",
      "mean absolute error test:  78735.50474902311\n",
      "r2 predict train:  0.8450948318151117\n",
      "r2 predict test:  0.8452833620283181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0, train_size = .7)\n",
    "# Define model\n",
    "# Fit model\n",
    "# gam.fit(train_X, train_y)\n",
    "#get predicted prices on validation data\n",
    "val_predictions = gam.predict(val_X)\n",
    "train_predictions = gam.predict(train_X)\n",
    "print(\"mean absolute error train: \" , mean_absolute_error(train_y, train_predictions))\n",
    "print(\"mean absolute error test: \" , mean_absolute_error(val_y, val_predictions))\n",
    "print(\"r2 predict train: \" , r2_score(train_y, train_predictions))\n",
    "print(\"r2 predict test: \" , r2_score(val_y, val_predictions))\n",
    "#print(cross_val_score(gam, train_X, train_y, cv=3, scoring = 'r2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Zillow_KC_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[used_cols], df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = gam.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error test:  75861.96433087518\n",
      "r2 predict test:  0.8995228089915434\n"
     ]
    }
   ],
   "source": [
    "print(\"mean absolute error test: \" , mean_absolute_error(y_preds, df[target]))\n",
    "print(\"r2 predict test: \" , r2_score(y_preds, df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['low_col_gams.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'low_col_gams.sav'\n",
    "joblib.dump(gam, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
